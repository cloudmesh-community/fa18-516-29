
Hadoop,Hive and Spark cluster set up on Amazon EC2 instances(Part-2):

The following section describes the installation of Hadoop on the 4 instances and the configurations required for the different config files:

Cluster Planning: We will have a 3 node Hadoop cluster with 1 as master and 3 as slaves.Each instance is T2.meduim type and has 4 GB of memory
and initially 8GB of physical storage.We will add more volume and upgrade the physical storage to 16GB.This configuration is fine for doing 
the initial cluster set up and running some map reduce jobs for test purpose,but definitely will not work for large datasets.For a 
substantial amount of data transfer,one should go for T2.Xlarge instances which have 16GB of memory and initially 32 GB of physical storage.
The only downside is that it will be expensive to own 4 such large instances.

Master and Slaves:There will be 1 master instance.This will have the namemode,resourcemanager and jobhistoryserver deamons running.
There will be 3 slave nodes where datanode and nodemanager deamons will run.To configure masters and slaves create 2 files with names
masters and slaves.Add the following to them:

masters file                               slaves file
namenode                                    datanode1
                                            datanode2
                                            datanode3

Hadoop installation:(Everything is done when logged in as ubuntu user)

 i. Before starting the installation,upgrade all the servers as a good practice by the below command.
      sudo apt-get update
   
 ii. Install java version8 in all the servers:
      sudo apt install openjdk-8-jdk
    
 iii. Download and install hadoop 2.9 is all the servers.
      wget http://apache.mirrors.tds.net/hadoop/common/hadoop-2.9.1/hadoop-2.9.1.tar.gz -P ~/hadoop_installation
    
 iv. Uncompress the tar file in any directory called hadoop home
      tar zxvf ~/hadoop_installation/hadoop-* -C ~/hadoop_home
 
 v. set up the env variables in all the .profile and .bashrc of all the servers
 
    export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
    export PATH=$PATH:$JAVA_HOME/bin
    export HADOOP_HOME=/home/ubuntu/hadoop_home/hadoop-2.9.1
    export PATH=$PATH:$HADOOP_HOME/bin
    export HADOOP_CONF_DIR=/home/ubuntu/hadoop_home/hadoop-2.9.1/etc/hadoop
   
  vi. Load profile in all the servers
     ~/.profile
     
  vii. Change the hadoop-env.sh in $HADOOP_HOME/etc/hadoop in all the instances to add the below line for JAVA_HOME.
     export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
     
  2. Hadoop configurations(The config files will be changed on all the instances):
  
    i. core-site.xml
    
        fs.defaultFS     hdfs://ec2-52-24-204-101.us-west-2.compute.amazonaws.com:9001(This is the master instance hostname,
                       9001 is the RPC port)
                       
        hadoop.tmp.dir  file:///home/ubuntu/hadoop_home/hadoop-2.9.1/hadoop_tmp(The filesystem should be the one where we are adding more
                       volume as there is lot of intermediate data which gets written here.
                       
.   ii. hdfs-site.xml

          dfs.namenode.name.dir  file:///home/ubuntu/hadoop_home/hadoop-2.9.1/hadoop_data/hdfs/namenode
                             (This is the namenode directory in the master instance which will have the fs image and edit logs)
                             
          dfs.datanode.data.dir  file:///home/ubuntu/hadoop_home/hadoop-2.9.1/hadoop_data/hdfs/datanode
                             (This is the directory in the slave nodes with the actual data blocks of distributed file system)
                             
          dfs.replication       2 (Initially only 2 considering the small size of physical storage)
        
     iii. mapred-site.xml
     
            mapreduce.framework.name   yarn
            yarn.app.mapreduce.am.resource.mb 3072
            mapreduce.map.memory.mb  512
            mapreduce.reduce.memory.mb 512
          
     iv. yarn-site.xml
       
           yarn.acl.enable  false
           yarn.resourcemanager.hostname ec2-52-24-204-101.us-west-2.compute.amazonaws.com
           yarn.nodemanager.aux-services mapreduce_shuffle
           yarn.nodemanager.vmem-check-enabled false
           yarn.nodemanager.resource.memory-mb 3072
           yarn.scheduler.maximum-allocation-mb 3072
           yarn.scheduler.minimum-allocation-mb 1536
           yarn.nodemanager.local-dirs ${hadoop.tmp.dir}/nm-local-dir
           
          

        
