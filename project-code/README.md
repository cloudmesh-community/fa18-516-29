# Secondary Sort Design Pattern in Spark and Mapreduce

:o: why is this not in your report?

:o: after a comma there is a space

:o: do not use word above

:o: markdown format errors such as lists, read about markdown syntax

## Introduction

The MapReduce framework automatically sorts the keys generated by mappers. This means that, before starting reducers, all intermediate key-value pairs generated by mappers are sorted by key (and not by value).In scenarios where we also want to sort the values in the reducer for example as in time series data,secondary sort design pattern is very helpful.

## Motivation:

For a large dataset,if we want to sort the values in the reducer for example [Key : list {Value1,Value2,Value3....}] where values should
also be sorted,then we have 2 options:

1.To bring all the data for a key in an array in a single reducer then sort them.This may not scale if there are too many values
for a single key.

2.The second option is to leverage the sorting ability of map reduce framework where the data sent to the reducer is already sorted
by the key of the data in key:value pair.Here,the approach is to introduce the value by which it is to be sorted in the key of the
data as a composite key {natural key,value to be sorted} and then the framework will do the sorting on multiple nodes without shuffling
and bringing the entire data in one node.

## Implementation in MapReduce:

For example,we have the data:
 
 2012, 50
 2012, 45
 2012, 35
 2012, 10
 2001, 46
 2001, 47
 2001, 48
 2001, 40
 2005, 20
 2005, 01 

We want to achieve the following output,where it is sorted by key(1st column) as well as by value(2nd column):

2001    40
2001    46
2001    47
2001    48
2005    1
2005    20
2012    10
2012    35
2012    45
2012    50

Then using mapreduce framework we have to do the following:

1.Tell the framework how to sort the reducer keys.This done by making a composite key which consists of both natural key and the
actula value and attaching a compartor to it which will compare the 2 composite keys based on natual key and actual value and
sort the data accordingly for sending it to the reducer.This sorting is done before the reduce phase.

2.Secondly, we have to introduce a custom partitioner which will partition the data and send it to the reducers based on actual
natural keys.Since we have modified the natural key to include the value column as well,we have to specify in custom partitioner
to only include natural key while partitioning the data.

3.Lastly,once the data reaches the reducer we have to tell the reduce method to group the data by the actual natural key and
  not by the entire composite key.
  
  The above steps will ensure that the data is sorted by the natural key and then by the desired value column for sorting.
  
 
  ## Reference:
  
  https://github.com/mahmoudparsian/data-algorithms-book
  

 
  
  
